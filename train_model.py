import pandas as pd
import numpy as np
import joblib
import time
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB  # Fastest model
from sklearn.linear_model import LogisticRegression  # More accurate
from sklearn.metrics import accuracy_score

# â³ Start timer to measure training time
start_time = time.time()

# ğŸ“‚ Load dataset
file_path = "emails.csv"
df = pd.read_csv(file_path)

# ğŸ” Check for missing values
df.dropna(inplace=True)

# ğŸ· Define features and labels
X = df["Email Content"]  # Email text
y = df["Label"]  # Phishing (1) or Legitimate (0)

# ğŸ Optimize training by using only 50,000 samples if dataset is too large
if len(df) > 50000:
    df = df.sample(n=50000, random_state=42)

# âœ¨ Convert text data to numerical vectors using TF-IDF
vectorizer = TfidfVectorizer(stop_words="english", max_features=5000)
X_tfidf = vectorizer.fit_transform(X)

# ğŸ¯ Split dataset (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# ğŸš€ Train Model (NaÃ¯ve Bayes for speed, Logistic Regression for accuracy)
model = MultinomialNB()  # Change to LogisticRegression() for better accuracy
model.fit(X_train, y_train)

# ğŸ¯ Evaluate Model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"âœ… Training Completed! Accuracy: {accuracy:.2%}")

# ğŸ’¾ Save Model and Vectorizer
joblib.dump(model, "phishing_model.pkl")
joblib.dump(vectorizer, "vectorizer.pkl")

# â³ Display total training time
end_time = time.time()
print(f"â³ Training Time: {end_time - start_time:.2f} seconds")
